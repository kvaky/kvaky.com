---

layout: post

title: Why and how I exported 500 of my couchsurfing contacts into google contacts

published: true

categories: Tech

excerpt_separator: <!--more-->

---

Recently I realized I had over 500 conversations on couchsurfing. Even though I have hosted/surfed at only about 10% of these people, I thought I could still utilize having chatted with those other 450. It would be cool to have a tool which, when given a location, would return me a list of people I have already been in contact with. Google contacts can do that, I just needed to get the data from couchsurfing to google. To do this, I:
1. Parsed my conversations [exported from couchsurfing](https://www.couchsurfing.com/preferences/privacy) to get profile ids and phone numbers,
1. Scraped the couchsurfing page to join profile ids with their names and locations, 
1. Exported the data to csv,
1. Imported the csv to google contacts.


The following is python jupyter notebook code I used to create the csv.

```python
from collections import defaultdict
from selenium import webdriver
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import json
import re
import pandas as pd
```

Load the exported data.


```python
with open("data.json") as fi:
    data = json.load(fi)

messages = data["messages"]["messages"]
```

Get profile ids and phone numbers of people that I chatted with.


```python
def get_number_from_message(msg: str):
    if msg is None:
        return ''
    match = re.search(r"((\+|00)[0-9 \-+]{8,})", msg)
    if match:
        return match.group(0).strip()
    else:
        return ''

MY_CS_ID = 2002965911
user_info = defaultdict(dict)
for convo in messages:
    convo_messages = convo["messages"]
    for message in convo_messages:
        author_id = message["author_id"]
        if author_id != MY_CS_ID:
            number = get_number_from_message(message["body"])
            user_info[author_id]["number"] = number
            if number != '':
                break
```

Open a window to log in so that I can view all member profiles.


```python
driver = webdriver.Firefox()
driver.get("http://www.couchsurfing.com")
```

After logging in, run the scraping itself.


```python
for i, user_id in enumerate(user_info):
    print(f"{user_id} {i+1}/{len(user_info)}")
    driver.get(f"https://couchsurfing.com/users/{user_id}")
    if "Deactivated User" in driver.page_source:
        continue
    name = WebDriverWait(driver, 5).until(
        EC.presence_of_element_located((By.XPATH, "/html/body/main/div[1]/div/div/div[1]/span/a/span"))
    ).text
    try:
        location = driver.find_element_by_xpath("/html/body/main/div[1]/div[1]/div/div[1]/a").text
    except NoSuchElementException:
        try:
            location = driver.find_element_by_xpath("/html/body/main/div[1]/div/div/div[1]/span[2]").text
        except NoSuchElementException:
            location = ''
    user_info[user_id]["name"] = name
    user_info[user_id]["location"] = location
```

Remove accounts that were deactivated.


```python
user_info_cleaned = {k: v for k, v in user_info.items() if "name" in v}
```

Export the data to csv.


```python
table = []
for user_id, user in user_info_cleaned.items():
    row = {
        "Given Name": user["name"].split()[0],
        "Family Name": " ".join(user["name"].split()[1:]),
        "Phone 1 - Type": "Mobile",
        "Phone 1 - Value": user["number"],
        "Address 1 - Type": "Home",
        "Address 1 - Formatted": user["location"],
        "Website 1 - Type": "",
        "Website 1 - Value": f"couchsurfing.com/users/{user_id}"
    }
    table.append(row)

pd.DataFrame(table).to_csv("cs_contacts.csv",index = False)
```

Now I have a convenient way to reach all these 488 people based on location.
